Log file created at: 2016/04/27 16-42-47
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0427 16:42:48.142171  2636 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2
test_interval: 4
base_lr: 0.01
display: 100
max_iter: 213
lr_policy: "step"
gamma: 0.1
momentum: 0.99
weight_decay: 0.005
stepsize: 30000
snapshot_prefix: "snapshots/avasm"
solver_mode: GPU
net: "/home/pierre/masterarbeit/twoears/models/avasm/train_val.prototxt"
snapshot_after_train: true
I0427 16:42:48.142221  2636 solver.cpp:91] Creating training net from net file: /home/pierre/masterarbeit/twoears/models/avasm/train_val.prototxt
I0427 16:42:48.143306  2636 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0427 16:42:48.143317  2636 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0427 16:42:48.143551  2636 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_train.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_train.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 75
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 9
    kernel_w: 9
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "dropip2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "ip2"
  top: "score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0427 16:42:48.143630  2636 layer_factory.hpp:77] Creating layer data
I0427 16:42:48.143646  2636 net.cpp:91] Creating Layer data
I0427 16:42:48.143656  2636 net.cpp:399] data -> amsFeatures
I0427 16:42:48.143681  2636 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_train.txt
I0427 16:42:48.144098  2636 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0427 16:42:48.145262  2636 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0427 16:42:48.203761  2636 net.cpp:141] Setting up data
I0427 16:42:48.203806  2636 net.cpp:148] Top shape: 16 1 513 105 (861840)
I0427 16:42:48.203814  2636 net.cpp:156] Memory required for data: 3447360
I0427 16:42:48.203827  2636 layer_factory.hpp:77] Creating layer data
I0427 16:42:48.203850  2636 net.cpp:91] Creating Layer data
I0427 16:42:48.203860  2636 net.cpp:399] data -> label
I0427 16:42:48.203878  2636 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_train.txt
I0427 16:42:48.204093  2636 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0427 16:42:48.205812  2636 net.cpp:141] Setting up data
I0427 16:42:48.205829  2636 net.cpp:148] Top shape: 16 2 (32)
I0427 16:42:48.205835  2636 net.cpp:156] Memory required for data: 3447488
I0427 16:42:48.205843  2636 layer_factory.hpp:77] Creating layer conv1
I0427 16:42:48.205868  2636 net.cpp:91] Creating Layer conv1
I0427 16:42:48.205874  2636 net.cpp:425] conv1 <- amsFeatures
I0427 16:42:48.205885  2636 net.cpp:399] conv1 -> conv1
I0427 16:42:48.207655  2636 net.cpp:141] Setting up conv1
I0427 16:42:48.207676  2636 net.cpp:148] Top shape: 16 75 253 49 (14876400)
I0427 16:42:48.207682  2636 net.cpp:156] Memory required for data: 62953088
I0427 16:42:48.207706  2636 layer_factory.hpp:77] Creating layer relu1
I0427 16:42:48.207718  2636 net.cpp:91] Creating Layer relu1
I0427 16:42:48.207725  2636 net.cpp:425] relu1 <- conv1
I0427 16:42:48.207734  2636 net.cpp:386] relu1 -> conv1 (in-place)
I0427 16:42:48.207747  2636 net.cpp:141] Setting up relu1
I0427 16:42:48.207756  2636 net.cpp:148] Top shape: 16 75 253 49 (14876400)
I0427 16:42:48.207762  2636 net.cpp:156] Memory required for data: 122458688
I0427 16:42:48.207767  2636 layer_factory.hpp:77] Creating layer pool1
I0427 16:42:48.207778  2636 net.cpp:91] Creating Layer pool1
I0427 16:42:48.207784  2636 net.cpp:425] pool1 <- conv1
I0427 16:42:48.207793  2636 net.cpp:399] pool1 -> pool1
I0427 16:42:48.207850  2636 net.cpp:141] Setting up pool1
I0427 16:42:48.207862  2636 net.cpp:148] Top shape: 16 75 127 25 (3810000)
I0427 16:42:48.207867  2636 net.cpp:156] Memory required for data: 137698688
I0427 16:42:48.207873  2636 layer_factory.hpp:77] Creating layer conv2
I0427 16:42:48.207887  2636 net.cpp:91] Creating Layer conv2
I0427 16:42:48.207893  2636 net.cpp:425] conv2 <- pool1
I0427 16:42:48.207903  2636 net.cpp:399] conv2 -> conv2
I0427 16:42:48.210160  2636 net.cpp:141] Setting up conv2
I0427 16:42:48.210181  2636 net.cpp:148] Top shape: 16 64 125 23 (2944000)
I0427 16:42:48.210187  2636 net.cpp:156] Memory required for data: 149474688
I0427 16:42:48.210204  2636 layer_factory.hpp:77] Creating layer pool2
I0427 16:42:48.210216  2636 net.cpp:91] Creating Layer pool2
I0427 16:42:48.210222  2636 net.cpp:425] pool2 <- conv2
I0427 16:42:48.210233  2636 net.cpp:399] pool2 -> pool2
I0427 16:42:48.210291  2636 net.cpp:141] Setting up pool2
I0427 16:42:48.210304  2636 net.cpp:148] Top shape: 16 64 63 12 (774144)
I0427 16:42:48.210309  2636 net.cpp:156] Memory required for data: 152571264
I0427 16:42:48.210316  2636 layer_factory.hpp:77] Creating layer relu2
I0427 16:42:48.210325  2636 net.cpp:91] Creating Layer relu2
I0427 16:42:48.210331  2636 net.cpp:425] relu2 <- pool2
I0427 16:42:48.210340  2636 net.cpp:386] relu2 -> pool2 (in-place)
I0427 16:42:48.210350  2636 net.cpp:141] Setting up relu2
I0427 16:42:48.210360  2636 net.cpp:148] Top shape: 16 64 63 12 (774144)
I0427 16:42:48.210366  2636 net.cpp:156] Memory required for data: 155667840
I0427 16:42:48.210371  2636 layer_factory.hpp:77] Creating layer ip2
I0427 16:42:48.210389  2636 net.cpp:91] Creating Layer ip2
I0427 16:42:48.210397  2636 net.cpp:425] ip2 <- pool2
I0427 16:42:48.210407  2636 net.cpp:399] ip2 -> ip2
I0427 16:42:48.301898  2636 net.cpp:141] Setting up ip2
I0427 16:42:48.301940  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.301950  2636 net.cpp:156] Memory required for data: 155676032
I0427 16:42:48.301977  2636 layer_factory.hpp:77] Creating layer relu2
I0427 16:42:48.301995  2636 net.cpp:91] Creating Layer relu2
I0427 16:42:48.302005  2636 net.cpp:425] relu2 <- ip2
I0427 16:42:48.302018  2636 net.cpp:386] relu2 -> ip2 (in-place)
I0427 16:42:48.302037  2636 net.cpp:141] Setting up relu2
I0427 16:42:48.302047  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.302052  2636 net.cpp:156] Memory required for data: 155684224
I0427 16:42:48.302057  2636 layer_factory.hpp:77] Creating layer dropip2
I0427 16:42:48.302079  2636 net.cpp:91] Creating Layer dropip2
I0427 16:42:48.302085  2636 net.cpp:425] dropip2 <- ip2
I0427 16:42:48.302094  2636 net.cpp:386] dropip2 -> ip2 (in-place)
I0427 16:42:48.302136  2636 net.cpp:141] Setting up dropip2
I0427 16:42:48.302148  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.302155  2636 net.cpp:156] Memory required for data: 155692416
I0427 16:42:48.302161  2636 layer_factory.hpp:77] Creating layer score
I0427 16:42:48.302178  2636 net.cpp:91] Creating Layer score
I0427 16:42:48.302187  2636 net.cpp:425] score <- ip2
I0427 16:42:48.302201  2636 net.cpp:399] score -> score
I0427 16:42:48.302415  2636 net.cpp:141] Setting up score
I0427 16:42:48.302436  2636 net.cpp:148] Top shape: 16 2 (32)
I0427 16:42:48.302443  2636 net.cpp:156] Memory required for data: 155692544
I0427 16:42:48.302456  2636 layer_factory.hpp:77] Creating layer loss
I0427 16:42:48.302474  2636 net.cpp:91] Creating Layer loss
I0427 16:42:48.302480  2636 net.cpp:425] loss <- score
I0427 16:42:48.302489  2636 net.cpp:425] loss <- label
I0427 16:42:48.302498  2636 net.cpp:399] loss -> loss
I0427 16:42:48.302569  2636 net.cpp:141] Setting up loss
I0427 16:42:48.302582  2636 net.cpp:148] Top shape: (1)
I0427 16:42:48.302588  2636 net.cpp:151]     with loss weight 1
I0427 16:42:48.302611  2636 net.cpp:156] Memory required for data: 155692548
I0427 16:42:48.302618  2636 net.cpp:217] loss needs backward computation.
I0427 16:42:48.302625  2636 net.cpp:217] score needs backward computation.
I0427 16:42:48.302633  2636 net.cpp:217] dropip2 needs backward computation.
I0427 16:42:48.302639  2636 net.cpp:217] relu2 needs backward computation.
I0427 16:42:48.302644  2636 net.cpp:217] ip2 needs backward computation.
I0427 16:42:48.302650  2636 net.cpp:217] relu2 needs backward computation.
I0427 16:42:48.302656  2636 net.cpp:217] pool2 needs backward computation.
I0427 16:42:48.302662  2636 net.cpp:217] conv2 needs backward computation.
I0427 16:42:48.302669  2636 net.cpp:217] pool1 needs backward computation.
I0427 16:42:48.302675  2636 net.cpp:217] relu1 needs backward computation.
I0427 16:42:48.302681  2636 net.cpp:217] conv1 needs backward computation.
I0427 16:42:48.302688  2636 net.cpp:219] data does not need backward computation.
I0427 16:42:48.302695  2636 net.cpp:219] data does not need backward computation.
I0427 16:42:48.302700  2636 net.cpp:261] This network produces output loss
I0427 16:42:48.302714  2636 net.cpp:274] Network initialization done.
I0427 16:42:48.303515  2636 solver.cpp:181] Creating test net (#0) specified by net file: /home/pierre/masterarbeit/twoears/models/avasm/train_val.prototxt
I0427 16:42:48.303567  2636 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0427 16:42:48.303577  2636 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0427 16:42:48.303824  2636 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_test.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_test.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 75
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 9
    kernel_w: 9
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "dropip2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "ip2"
  top: "score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0427 16:42:48.303903  2636 layer_factory.hpp:77] Creating layer data
I0427 16:42:48.303916  2636 net.cpp:91] Creating Layer data
I0427 16:42:48.303925  2636 net.cpp:399] data -> amsFeatures
I0427 16:42:48.303937  2636 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_test.txt
I0427 16:42:48.304177  2636 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0427 16:42:48.321686  2636 net.cpp:141] Setting up data
I0427 16:42:48.321722  2636 net.cpp:148] Top shape: 16 1 513 105 (861840)
I0427 16:42:48.321729  2636 net.cpp:156] Memory required for data: 3447360
I0427 16:42:48.321741  2636 layer_factory.hpp:77] Creating layer data
I0427 16:42:48.321763  2636 net.cpp:91] Creating Layer data
I0427 16:42:48.321771  2636 net.cpp:399] data -> label
I0427 16:42:48.321790  2636 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/pierre/masterarbeit/twoears/avasm/hdf5/avasm_data_test.txt
I0427 16:42:48.321986  2636 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0427 16:42:48.322793  2636 net.cpp:141] Setting up data
I0427 16:42:48.322808  2636 net.cpp:148] Top shape: 16 2 (32)
I0427 16:42:48.322814  2636 net.cpp:156] Memory required for data: 3447488
I0427 16:42:48.322820  2636 layer_factory.hpp:77] Creating layer conv1
I0427 16:42:48.322840  2636 net.cpp:91] Creating Layer conv1
I0427 16:42:48.322847  2636 net.cpp:425] conv1 <- amsFeatures
I0427 16:42:48.322860  2636 net.cpp:399] conv1 -> conv1
I0427 16:42:48.323346  2636 net.cpp:141] Setting up conv1
I0427 16:42:48.323361  2636 net.cpp:148] Top shape: 16 75 253 49 (14876400)
I0427 16:42:48.323367  2636 net.cpp:156] Memory required for data: 62953088
I0427 16:42:48.323384  2636 layer_factory.hpp:77] Creating layer relu1
I0427 16:42:48.323392  2636 net.cpp:91] Creating Layer relu1
I0427 16:42:48.323398  2636 net.cpp:425] relu1 <- conv1
I0427 16:42:48.323406  2636 net.cpp:386] relu1 -> conv1 (in-place)
I0427 16:42:48.323417  2636 net.cpp:141] Setting up relu1
I0427 16:42:48.323426  2636 net.cpp:148] Top shape: 16 75 253 49 (14876400)
I0427 16:42:48.323432  2636 net.cpp:156] Memory required for data: 122458688
I0427 16:42:48.323438  2636 layer_factory.hpp:77] Creating layer pool1
I0427 16:42:48.323451  2636 net.cpp:91] Creating Layer pool1
I0427 16:42:48.323457  2636 net.cpp:425] pool1 <- conv1
I0427 16:42:48.323467  2636 net.cpp:399] pool1 -> pool1
I0427 16:42:48.323525  2636 net.cpp:141] Setting up pool1
I0427 16:42:48.323536  2636 net.cpp:148] Top shape: 16 75 127 25 (3810000)
I0427 16:42:48.323542  2636 net.cpp:156] Memory required for data: 137698688
I0427 16:42:48.323549  2636 layer_factory.hpp:77] Creating layer conv2
I0427 16:42:48.323562  2636 net.cpp:91] Creating Layer conv2
I0427 16:42:48.323568  2636 net.cpp:425] conv2 <- pool1
I0427 16:42:48.323578  2636 net.cpp:399] conv2 -> conv2
I0427 16:42:48.324460  2636 net.cpp:141] Setting up conv2
I0427 16:42:48.324475  2636 net.cpp:148] Top shape: 16 64 125 23 (2944000)
I0427 16:42:48.324481  2636 net.cpp:156] Memory required for data: 149474688
I0427 16:42:48.324494  2636 layer_factory.hpp:77] Creating layer pool2
I0427 16:42:48.324506  2636 net.cpp:91] Creating Layer pool2
I0427 16:42:48.324513  2636 net.cpp:425] pool2 <- conv2
I0427 16:42:48.324522  2636 net.cpp:399] pool2 -> pool2
I0427 16:42:48.324584  2636 net.cpp:141] Setting up pool2
I0427 16:42:48.324596  2636 net.cpp:148] Top shape: 16 64 63 12 (774144)
I0427 16:42:48.324604  2636 net.cpp:156] Memory required for data: 152571264
I0427 16:42:48.324610  2636 layer_factory.hpp:77] Creating layer relu2
I0427 16:42:48.324620  2636 net.cpp:91] Creating Layer relu2
I0427 16:42:48.324627  2636 net.cpp:425] relu2 <- pool2
I0427 16:42:48.324636  2636 net.cpp:386] relu2 -> pool2 (in-place)
I0427 16:42:48.324647  2636 net.cpp:141] Setting up relu2
I0427 16:42:48.324656  2636 net.cpp:148] Top shape: 16 64 63 12 (774144)
I0427 16:42:48.324662  2636 net.cpp:156] Memory required for data: 155667840
I0427 16:42:48.324667  2636 layer_factory.hpp:77] Creating layer ip2
I0427 16:42:48.324681  2636 net.cpp:91] Creating Layer ip2
I0427 16:42:48.324687  2636 net.cpp:425] ip2 <- pool2
I0427 16:42:48.324697  2636 net.cpp:399] ip2 -> ip2
I0427 16:42:48.415868  2636 net.cpp:141] Setting up ip2
I0427 16:42:48.415906  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.415913  2636 net.cpp:156] Memory required for data: 155676032
I0427 16:42:48.415937  2636 layer_factory.hpp:77] Creating layer relu2
I0427 16:42:48.415952  2636 net.cpp:91] Creating Layer relu2
I0427 16:42:48.415961  2636 net.cpp:425] relu2 <- ip2
I0427 16:42:48.415972  2636 net.cpp:386] relu2 -> ip2 (in-place)
I0427 16:42:48.415987  2636 net.cpp:141] Setting up relu2
I0427 16:42:48.415995  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.416002  2636 net.cpp:156] Memory required for data: 155684224
I0427 16:42:48.416007  2636 layer_factory.hpp:77] Creating layer dropip2
I0427 16:42:48.416018  2636 net.cpp:91] Creating Layer dropip2
I0427 16:42:48.416024  2636 net.cpp:425] dropip2 <- ip2
I0427 16:42:48.416033  2636 net.cpp:386] dropip2 -> ip2 (in-place)
I0427 16:42:48.416074  2636 net.cpp:141] Setting up dropip2
I0427 16:42:48.416085  2636 net.cpp:148] Top shape: 16 128 (2048)
I0427 16:42:48.416090  2636 net.cpp:156] Memory required for data: 155692416
I0427 16:42:48.416097  2636 layer_factory.hpp:77] Creating layer score
I0427 16:42:48.416111  2636 net.cpp:91] Creating Layer score
I0427 16:42:48.416117  2636 net.cpp:425] score <- ip2
I0427 16:42:48.416128  2636 net.cpp:399] score -> score
I0427 16:42:48.416280  2636 net.cpp:141] Setting up score
I0427 16:42:48.416296  2636 net.cpp:148] Top shape: 16 2 (32)
I0427 16:42:48.416301  2636 net.cpp:156] Memory required for data: 155692544
I0427 16:42:48.416313  2636 layer_factory.hpp:77] Creating layer loss
I0427 16:42:48.416326  2636 net.cpp:91] Creating Layer loss
I0427 16:42:48.416332  2636 net.cpp:425] loss <- score
I0427 16:42:48.416340  2636 net.cpp:425] loss <- label
I0427 16:42:48.416349  2636 net.cpp:399] loss -> loss
I0427 16:42:48.416410  2636 net.cpp:141] Setting up loss
I0427 16:42:48.416424  2636 net.cpp:148] Top shape: (1)
I0427 16:42:48.416429  2636 net.cpp:151]     with loss weight 1
I0427 16:42:48.416446  2636 net.cpp:156] Memory required for data: 155692548
I0427 16:42:48.416453  2636 net.cpp:217] loss needs backward computation.
I0427 16:42:48.416460  2636 net.cpp:217] score needs backward computation.
I0427 16:42:48.416467  2636 net.cpp:217] dropip2 needs backward computation.
I0427 16:42:48.416473  2636 net.cpp:217] relu2 needs backward computation.
I0427 16:42:48.416479  2636 net.cpp:217] ip2 needs backward computation.
I0427 16:42:48.416486  2636 net.cpp:217] relu2 needs backward computation.
I0427 16:42:48.416491  2636 net.cpp:217] pool2 needs backward computation.
I0427 16:42:48.416497  2636 net.cpp:217] conv2 needs backward computation.
I0427 16:42:48.416504  2636 net.cpp:217] pool1 needs backward computation.
I0427 16:42:48.416510  2636 net.cpp:217] relu1 needs backward computation.
I0427 16:42:48.416517  2636 net.cpp:217] conv1 needs backward computation.
I0427 16:42:48.416523  2636 net.cpp:219] data does not need backward computation.
I0427 16:42:48.416529  2636 net.cpp:219] data does not need backward computation.
I0427 16:42:48.416535  2636 net.cpp:261] This network produces output loss
I0427 16:42:48.416549  2636 net.cpp:274] Network initialization done.
I0427 16:42:48.416625  2636 solver.cpp:60] Solver scaffolding done.
I0427 16:42:48.417181  0000 main.py:00] Solving
I0427 16:42:48.417906  2636 solver.cpp:337] Iteration 0, Testing net (#0)
I0427 16:42:48.463613  2636 solver.cpp:404]     Test net output #0: loss = 1.39248 (* 1 = 1.39248 loss)
I0427 16:42:48.492982  2636 solver.cpp:228] Iteration 0, loss = 1.3743
I0427 16:42:48.493010  2636 solver.cpp:244]     Train net output #0: loss = 1.3743 (* 1 = 1.3743 loss)
I0427 16:42:48.493024  2636 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0427 16:42:48.561909  0000 main.py:00] Test net output #1: accuracy = 0.1875
I0427 16:42:48.784844  2636 solver.cpp:337] Iteration 4, Testing net (#0)
I0427 16:42:48.868860  2636 solver.cpp:404]     Test net output #0: loss = 1.42309 (* 1 = 1.42309 loss)
I0427 16:42:48.957325  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:49.115375  2636 solver.cpp:337] Iteration 8, Testing net (#0)
I0427 16:42:49.199384  2636 solver.cpp:404]     Test net output #0: loss = 1.43537 (* 1 = 1.43537 loss)
I0427 16:42:49.287611  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:49.445554  2636 solver.cpp:337] Iteration 12, Testing net (#0)
I0427 16:42:49.529391  2636 solver.cpp:404]     Test net output #0: loss = 1.37423 (* 1 = 1.37423 loss)
I0427 16:42:49.617626  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:49.775327  2636 solver.cpp:337] Iteration 16, Testing net (#0)
I0427 16:42:49.859520  2636 solver.cpp:404]     Test net output #0: loss = 1.38603 (* 1 = 1.38603 loss)
I0427 16:42:49.948309  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:50.106124  2636 solver.cpp:337] Iteration 20, Testing net (#0)
I0427 16:42:50.189870  2636 solver.cpp:404]     Test net output #0: loss = 1.38828 (* 1 = 1.38828 loss)
I0427 16:42:50.278032  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:50.436053  2636 solver.cpp:337] Iteration 24, Testing net (#0)
I0427 16:42:50.520040  2636 solver.cpp:404]     Test net output #0: loss = 1.33512 (* 1 = 1.33512 loss)
I0427 16:42:50.608200  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:50.766072  2636 solver.cpp:337] Iteration 28, Testing net (#0)
I0427 16:42:50.849972  2636 solver.cpp:404]     Test net output #0: loss = 1.33309 (* 1 = 1.33309 loss)
I0427 16:42:50.938119  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:51.100055  2636 solver.cpp:337] Iteration 32, Testing net (#0)
I0427 16:42:51.183866  2636 solver.cpp:404]     Test net output #0: loss = 1.3814 (* 1 = 1.3814 loss)
I0427 16:42:51.272069  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:51.429997  2636 solver.cpp:337] Iteration 36, Testing net (#0)
I0427 16:42:51.513952  2636 solver.cpp:404]     Test net output #0: loss = 1.36892 (* 1 = 1.36892 loss)
I0427 16:42:51.602102  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:51.759949  2636 solver.cpp:337] Iteration 40, Testing net (#0)
I0427 16:42:51.844019  2636 solver.cpp:404]     Test net output #0: loss = 1.3072 (* 1 = 1.3072 loss)
I0427 16:42:51.932197  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:52.090168  2636 solver.cpp:337] Iteration 44, Testing net (#0)
I0427 16:42:52.173929  2636 solver.cpp:404]     Test net output #0: loss = 1.31271 (* 1 = 1.31271 loss)
I0427 16:42:52.262232  0000 main.py:00] Test net output #1: accuracy = 0.0
I0427 16:42:52.420159  2636 solver.cpp:337] Iteration 48, Testing net (#0)
I0427 16:42:52.504081  2636 solver.cpp:404]     Test net output #0: loss = 1.24255 (* 1 = 1.24255 loss)
I0427 16:42:52.592331  0000 main.py:00] Test net output #1: accuracy = 0.5
I0427 16:42:52.750161  2636 solver.cpp:337] Iteration 52, Testing net (#0)
I0427 16:42:52.834028  2636 solver.cpp:404]     Test net output #0: loss = 1.20724 (* 1 = 1.20724 loss)
I0427 16:42:52.922141  0000 main.py:00] Test net output #1: accuracy = 0.125
I0427 16:42:53.080101  2636 solver.cpp:337] Iteration 56, Testing net (#0)
I0427 16:42:53.164073  2636 solver.cpp:404]     Test net output #0: loss = 1.28844 (* 1 = 1.28844 loss)
I0427 16:42:53.252187  0000 main.py:00] Test net output #1: accuracy = 0.3125
I0427 16:42:53.410373  2636 solver.cpp:337] Iteration 60, Testing net (#0)
I0427 16:42:53.494302  2636 solver.cpp:404]     Test net output #0: loss = 1.21164 (* 1 = 1.21164 loss)
I0427 16:42:53.582957  0000 main.py:00] Test net output #1: accuracy = 0.5
I0427 16:42:53.740803  2636 solver.cpp:337] Iteration 64, Testing net (#0)
I0427 16:42:53.824847  2636 solver.cpp:404]     Test net output #0: loss = 0.847704 (* 1 = 0.847704 loss)
I0427 16:42:53.913023  0000 main.py:00] Test net output #1: accuracy = 0.4375
I0427 16:42:54.070817  2636 solver.cpp:337] Iteration 68, Testing net (#0)
I0427 16:42:54.154808  2636 solver.cpp:404]     Test net output #0: loss = 1.06666 (* 1 = 1.06666 loss)
I0427 16:42:54.243096  0000 main.py:00] Test net output #1: accuracy = 0.75
I0427 16:42:54.400993  2636 solver.cpp:337] Iteration 72, Testing net (#0)
I0427 16:42:54.485057  2636 solver.cpp:404]     Test net output #0: loss = 1.59707 (* 1 = 1.59707 loss)
I0427 16:42:54.573446  0000 main.py:00] Test net output #1: accuracy = 0.6875
I0427 16:42:54.731156  2636 solver.cpp:337] Iteration 76, Testing net (#0)
I0427 16:42:54.815129  2636 solver.cpp:404]     Test net output #0: loss = 1.32556 (* 1 = 1.32556 loss)
I0427 16:42:54.903363  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:55.061285  2636 solver.cpp:337] Iteration 80, Testing net (#0)
I0427 16:42:55.145169  2636 solver.cpp:404]     Test net output #0: loss = 0.930739 (* 1 = 0.930739 loss)
I0427 16:42:55.233386  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:42:55.391441  2636 solver.cpp:337] Iteration 84, Testing net (#0)
I0427 16:42:55.475385  2636 solver.cpp:404]     Test net output #0: loss = 1.0185 (* 1 = 1.0185 loss)
I0427 16:42:55.563760  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:55.721529  2636 solver.cpp:337] Iteration 88, Testing net (#0)
I0427 16:42:55.805565  2636 solver.cpp:404]     Test net output #0: loss = 1.79055 (* 1 = 1.79055 loss)
I0427 16:42:55.893619  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:56.051450  2636 solver.cpp:337] Iteration 92, Testing net (#0)
I0427 16:42:56.135387  2636 solver.cpp:404]     Test net output #0: loss = 1.04028 (* 1 = 1.04028 loss)
I0427 16:42:56.223690  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:56.381556  2636 solver.cpp:337] Iteration 96, Testing net (#0)
I0427 16:42:56.465572  2636 solver.cpp:404]     Test net output #0: loss = 1.03293 (* 1 = 1.03293 loss)
I0427 16:42:56.553781  0000 main.py:00] Test net output #1: accuracy = 0.3125
I0427 16:42:56.711341  2636 solver.cpp:337] Iteration 100, Testing net (#0)
I0427 16:42:56.795408  2636 solver.cpp:404]     Test net output #0: loss = 1.11476 (* 1 = 1.11476 loss)
I0427 16:42:56.814748  2636 solver.cpp:228] Iteration 100, loss = 0.867136
I0427 16:42:56.814775  2636 solver.cpp:244]     Train net output #0: loss = 0.867136 (* 1 = 0.867136 loss)
I0427 16:42:56.814786  2636 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0427 16:42:56.883543  0000 main.py:00] Test net output #1: accuracy = 0.75
I0427 16:42:57.041352  2636 solver.cpp:337] Iteration 104, Testing net (#0)
I0427 16:42:57.125221  2636 solver.cpp:404]     Test net output #0: loss = 1.50907 (* 1 = 1.50907 loss)
I0427 16:42:57.213421  0000 main.py:00] Test net output #1: accuracy = 0.6875
I0427 16:42:57.371309  2636 solver.cpp:337] Iteration 108, Testing net (#0)
I0427 16:42:57.455376  2636 solver.cpp:404]     Test net output #0: loss = 1.38415 (* 1 = 1.38415 loss)
I0427 16:42:57.544313  0000 main.py:00] Test net output #1: accuracy = 0.75
I0427 16:42:57.702175  2636 solver.cpp:337] Iteration 112, Testing net (#0)
I0427 16:42:57.786150  2636 solver.cpp:404]     Test net output #0: loss = 1.68635 (* 1 = 1.68635 loss)
I0427 16:42:57.874319  0000 main.py:00] Test net output #1: accuracy = 0.5
I0427 16:42:58.032156  2636 solver.cpp:337] Iteration 116, Testing net (#0)
I0427 16:42:58.116056  2636 solver.cpp:404]     Test net output #0: loss = 1.26432 (* 1 = 1.26432 loss)
I0427 16:42:58.204238  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:58.362031  2636 solver.cpp:337] Iteration 120, Testing net (#0)
I0427 16:42:58.446079  2636 solver.cpp:404]     Test net output #0: loss = 2.61835 (* 1 = 2.61835 loss)
I0427 16:42:58.534351  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:42:58.692179  2636 solver.cpp:337] Iteration 124, Testing net (#0)
I0427 16:42:58.776108  2636 solver.cpp:404]     Test net output #0: loss = 2.4693 (* 1 = 2.4693 loss)
I0427 16:42:58.864406  0000 main.py:00] Test net output #1: accuracy = 0.8125
I0427 16:42:59.022269  2636 solver.cpp:337] Iteration 128, Testing net (#0)
I0427 16:42:59.106091  2636 solver.cpp:404]     Test net output #0: loss = 1.85562 (* 1 = 1.85562 loss)
I0427 16:42:59.194189  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:42:59.352144  2636 solver.cpp:337] Iteration 132, Testing net (#0)
I0427 16:42:59.436081  2636 solver.cpp:404]     Test net output #0: loss = 2.35952 (* 1 = 2.35952 loss)
I0427 16:42:59.524409  0000 main.py:00] Test net output #1: accuracy = 0.75
I0427 16:42:59.682296  2636 solver.cpp:337] Iteration 136, Testing net (#0)
I0427 16:42:59.766353  2636 solver.cpp:404]     Test net output #0: loss = 3.57125 (* 1 = 3.57125 loss)
I0427 16:42:59.854598  0000 main.py:00] Test net output #1: accuracy = 0.6875
I0427 16:43:00.012385  2636 solver.cpp:337] Iteration 140, Testing net (#0)
I0427 16:43:00.096330  2636 solver.cpp:404]     Test net output #0: loss = 5.38943 (* 1 = 5.38943 loss)
I0427 16:43:00.184425  0000 main.py:00] Test net output #1: accuracy = 0.875
I0427 16:43:00.342453  2636 solver.cpp:337] Iteration 144, Testing net (#0)
I0427 16:43:00.426295  2636 solver.cpp:404]     Test net output #0: loss = 1.12275 (* 1 = 1.12275 loss)
I0427 16:43:00.514563  0000 main.py:00] Test net output #1: accuracy = 0.3125
I0427 16:43:00.672459  2636 solver.cpp:337] Iteration 148, Testing net (#0)
I0427 16:43:00.756399  2636 solver.cpp:404]     Test net output #0: loss = 1.13499 (* 1 = 1.13499 loss)
I0427 16:43:00.844623  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:43:01.002352  2636 solver.cpp:337] Iteration 152, Testing net (#0)
I0427 16:43:01.086405  2636 solver.cpp:404]     Test net output #0: loss = 1.54934 (* 1 = 1.54934 loss)
I0427 16:43:01.174643  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:43:01.332509  2636 solver.cpp:337] Iteration 156, Testing net (#0)
I0427 16:43:01.416556  2636 solver.cpp:404]     Test net output #0: loss = 2.60999 (* 1 = 2.60999 loss)
I0427 16:43:01.504767  0000 main.py:00] Test net output #1: accuracy = 0.6875
I0427 16:43:01.662569  2636 solver.cpp:337] Iteration 160, Testing net (#0)
I0427 16:43:01.746448  2636 solver.cpp:404]     Test net output #0: loss = 2.79235 (* 1 = 2.79235 loss)
I0427 16:43:01.834652  0000 main.py:00] Test net output #1: accuracy = 0.4375
I0427 16:43:01.992444  2636 solver.cpp:337] Iteration 164, Testing net (#0)
I0427 16:43:02.076412  2636 solver.cpp:404]     Test net output #0: loss = 2.88974 (* 1 = 2.88974 loss)
I0427 16:43:02.164799  0000 main.py:00] Test net output #1: accuracy = 0.8125
I0427 16:43:02.322628  2636 solver.cpp:337] Iteration 168, Testing net (#0)
I0427 16:43:02.406560  2636 solver.cpp:404]     Test net output #0: loss = 4.30398 (* 1 = 4.30398 loss)
I0427 16:43:02.494842  0000 main.py:00] Test net output #1: accuracy = 0.5
I0427 16:43:02.652633  2636 solver.cpp:337] Iteration 172, Testing net (#0)
I0427 16:43:02.736582  2636 solver.cpp:404]     Test net output #0: loss = 4.11233 (* 1 = 4.11233 loss)
I0427 16:43:02.824959  0000 main.py:00] Test net output #1: accuracy = 0.6875
I0427 16:43:02.983022  2636 solver.cpp:337] Iteration 176, Testing net (#0)
I0427 16:43:03.066862  2636 solver.cpp:404]     Test net output #0: loss = 4.81552 (* 1 = 4.81552 loss)
I0427 16:43:03.155102  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:43:03.312752  2636 solver.cpp:337] Iteration 180, Testing net (#0)
I0427 16:43:03.396662  2636 solver.cpp:404]     Test net output #0: loss = 2.28677 (* 1 = 2.28677 loss)
I0427 16:43:03.485018  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:43:03.642963  2636 solver.cpp:337] Iteration 184, Testing net (#0)
I0427 16:43:03.727008  2636 solver.cpp:404]     Test net output #0: loss = 2.76372 (* 1 = 2.76372 loss)
I0427 16:43:03.815409  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:43:03.973290  2636 solver.cpp:337] Iteration 188, Testing net (#0)
I0427 16:43:04.057271  2636 solver.cpp:404]     Test net output #0: loss = 3.24517 (* 1 = 3.24517 loss)
I0427 16:43:04.146456  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:43:04.304581  2636 solver.cpp:337] Iteration 192, Testing net (#0)
I0427 16:43:04.388540  2636 solver.cpp:404]     Test net output #0: loss = 2.061 (* 1 = 2.061 loss)
I0427 16:43:04.476880  0000 main.py:00] Test net output #1: accuracy = 0.1875
I0427 16:43:04.634522  2636 solver.cpp:337] Iteration 196, Testing net (#0)
I0427 16:43:04.718561  2636 solver.cpp:404]     Test net output #0: loss = 2.51523 (* 1 = 2.51523 loss)
I0427 16:43:04.806811  0000 main.py:00] Test net output #1: accuracy = 0.5625
I0427 16:43:04.964673  2636 solver.cpp:337] Iteration 200, Testing net (#0)
I0427 16:43:05.048746  2636 solver.cpp:404]     Test net output #0: loss = 2.17478 (* 1 = 2.17478 loss)
I0427 16:43:05.067982  2636 solver.cpp:228] Iteration 200, loss = 0.857093
I0427 16:43:05.068011  2636 solver.cpp:244]     Train net output #0: loss = 0.857093 (* 1 = 0.857093 loss)
I0427 16:43:05.068022  2636 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0427 16:43:05.136919  0000 main.py:00] Test net output #1: accuracy = 0.4375
I0427 16:43:05.294755  2636 solver.cpp:337] Iteration 204, Testing net (#0)
I0427 16:43:05.378684  2636 solver.cpp:404]     Test net output #0: loss = 1.94973 (* 1 = 1.94973 loss)
I0427 16:43:05.466891  0000 main.py:00] Test net output #1: accuracy = 0.625
I0427 16:43:05.624840  2636 solver.cpp:337] Iteration 208, Testing net (#0)
I0427 16:43:05.708751  2636 solver.cpp:404]     Test net output #0: loss = 1.59723 (* 1 = 1.59723 loss)
I0427 16:43:05.796889  0000 main.py:00] Test net output #1: accuracy = 0.375
I0427 16:43:05.954777  2636 solver.cpp:337] Iteration 212, Testing net (#0)
I0427 16:43:06.038707  2636 solver.cpp:404]     Test net output #0: loss = 1.60521 (* 1 = 1.60521 loss)
I0427 16:43:06.126972  0000 main.py:00] Test net output #1: accuracy = 0.375
